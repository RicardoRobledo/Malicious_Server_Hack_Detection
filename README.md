# üõ°Ô∏è Predicci√≥n de Hackeos Maliciosos en Servidores

## üìã Descripci√≥n del Proyecto

Este proyecto desarrolla un modelo predictivo para identificar patrones que indiquen la probabilidad de hackeos maliciosos en servidores. Con el aumento exponencial de los pagos digitales a nivel global, los ataques cibern√©ticos se han vuelto cada vez m√°s frecuentes, donde los hackers pueden comprometer datos utilizando √∫nicamente n√∫meros telef√≥nicos vinculados a cuentas bancarias.

**Objetivo:** Construir un sistema de detecci√≥n temprana que permita a los equipos de ciberseguridad prevenir ataques antes de que ocurran.

## üéØ Variable Objetivo

- **`MALICIOUS_OFFENSE`**: Indica si un servidor ser√° v√≠ctima de un hackeo malicioso

## üóÇÔ∏è Dataset

- **Fuente:** [Malicious Server Hack Dataset](https://www.kaggle.com/datasets/lplenka/malicious-server-hack)
- **Descarga autom√°tica:** Utilizando `kagglehub` para reproducibilidad
- **Variables:** Conjunto de caracter√≠sticas an√≥nimas que permiten la predicci√≥n

## üîß Metodolog√≠a y Pipeline

### 1. Preprocesamiento de Datos
- **Imputaci√≥n de valores faltantes:** `SimpleImputer` (mediana para num√©ricas, moda para categ√≥ricas)
- **Escalado de variables num√©ricas:** `StandardScaler`
- **Codificaci√≥n de categ√≥ricas:** `OneHotEncoder` con manejo de categor√≠as desconocidas
- **Arquitectura modular:** `ColumnTransformer` para procesamiento paralelo

### 2. Balanceo de Clases
Evaluaci√≥n exhaustiva de t√©cnicas de balanceo:

**T√©cnicas de Submuestreo:**
- TomekLinks
- EditedNearestNeighbours (ENN)
- RepeatedEditedNearestNeighbours (RENN)
- OneSidedSelection (OSS)
- NeighbourhoodCleaningRule (NCR)

**T√©cnicas de Sobremuestreo:**
- RandomOverSampler
- **SMOTE** (Synthetic Minority Oversampling Technique)
- BorderlineSMOTE
- **ADASYN** (Adaptive Synthetic Sampling)

### 3. Modelos Evaluados
- **Logistic Regression (LR)**
- **Linear Discriminant Analysis (LDA)**
- **Random Forest (RF)**
- **Gradient Boosting (GB)** ‚≠ê *Mejor rendimiento*
- **Support Vector Classifier (SVC)**
- **Gaussian Naive Bayes (NB)**

### 4. Calibraci√≥n de Probabilidades
- **CalibratedClassifierCV** con m√©todo isot√≥nico para obtener probabilidades bien calibradas

## üìä Resultados Principales

### Rendimiento por Modelo (G-Media):
| Modelo | Media | Desv. Est√°ndar |
|--------|-------|----------------|
| Gradient Boosting | **0.989** | 0.003 |
| Random Forest | 0.928 | 0.015 |
| SVC | 0.730 | 0.017 |
| LDA | 0.583 | 0.016 |
| Logistic Regression | 0.546 | 0.009 |
| Naive Bayes | 0.559 | 0.014 |

### Rendimiento por T√©cnica de Balanceo:
| T√©cnica | G-Media | Desv. Est√°ndar |
|---------|---------|----------------|
| **RandomOverSampler** | **0.995** | 0.002 |
| SMOTE | 0.994 | 0.003 |
| BorderlineSMOTE | 0.994 | 0.003 |
| ADASYN | 0.994 | 0.003 |
| RENN | 0.992 | 0.003 |

### Modelo Final: Gradient Boosting + ADASYN + Calibraci√≥n
- **Distribuci√≥n de predicciones en conjunto de prueba:**
  - Clase 0 (No hackeo): 8,004 instancias (33.55%)
  - Clase 1 (Hackeo): 7,899 instancias (33.11%)

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as

```python
# Core ML
scikit-learn
imbalanced-learn
numpy
pandas

# Modelos espec√≠ficos
RandomForestClassifier
GradientBoostingClassifier
SVM, Logistic Regression, etc.

# Balanceo de clases
SMOTE, ADASYN, TomekLinks, etc.

# Evaluaci√≥n
RepeatedStratifiedKFold
geometric_mean_score
CalibratedClassifierCV
```

## üéØ M√©tricas de Evaluaci√≥n

- **M√©trica principal:** G-Media (Geometric Mean Score)
- **Justificaci√≥n:** Ideal para problemas de clasificaci√≥n con clases desbalanceadas
- **Validaci√≥n:** Validaci√≥n cruzada estratificada repetida (5 folds, 3 repeticiones)
- **Robustez:** An√°lisis de estabilidad a trav√©s de m√∫ltiples ejecuciones

## üìà Conclusiones Clave

1. **Gradient Boosting** demostr√≥ ser el modelo m√°s efectivo para este problema
2. Las t√©cnicas de **sobremuestreo** superaron consistentemente a las de submuestreo
3. **RandomOverSampler** alcanz√≥ el mejor rendimiento (G-Media: 0.995)
4. La **calibraci√≥n de probabilidades** mejora la confiabilidad de las predicciones
5. El pipeline es robusto y generalizable para datos de producci√≥n

## üîÆ Aplicaciones Pr√°cticas

- **Detecci√≥n preventiva** de intentos de hackeo
- **Alertas tempranas** para equipos de ciberseguridad
- **Monitoreo continuo** de la seguridad de servidores
- **Optimizaci√≥n de recursos** de seguridad basada en riesgo

## üìù Notas T√©cnicas

- Pipeline completamente automatizado con `ColumnTransformer` e `imblearn.Pipeline`
- Manejo robusto de datos categ√≥ricos y num√©ricos
- Evaluaci√≥n comparativa exhaustiva de t√©cnicas de balanceo
- C√≥digo modular y reutilizable para diferentes conjuntos de datos

---

*Este proyecto forma parte de un sistema integral de ciberseguridad predictiva, dise√±ado para anticipar y prevenir ataques maliciosos en infraestructuras cr√≠ticas.*
